# WaterWise AI Environment Configuration
# ======================================

# Ollama AI Configuration
# ----------------------
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL_NAME=llama3.2
OLLAMA_TIMEOUT=300  # 5 minutes timeout for model operations
OLLAMA_MAX_RETRIES=3  # Number of retry attempts for model operations

# Flask Application Configuration
# ------------------------------
FLASK_ENV=production
FLASK_SECRET_KEY=generate_a_random_secret_key_here
FLASK_DEBUG=False
FLASK_APP=app.py

# Logging Configuration
# -------------------
LOG_LEVEL=INFO
LOG_FILE_PATH=/path/to/logs/waterwise.log
LOG_MAX_BYTES=10485760  # 10 MB max log file size
LOG_BACKUP_COUNT=5  # Number of backup log files to keep

# External API Tokens (Optional)
# ----------------------------
HUGGING_FACE_TOKEN=your_hugging_face_token
OPENAI_API_KEY=your_openai_api_key  # If using alternative models
ANTHROPIC_API_KEY=your_anthropic_api_key  # Fallback AI service

# Database Configuration (Optional)
# --------------------------------
DATABASE_URL=sqlite:///waterwise.db
DATABASE_POOL_SIZE=10
DATABASE_MAX_OVERFLOW=20

# Security Settings
# ----------------
CORS_ALLOWED_ORIGINS=https://waterwise-ai.com,http://localhost:5000
RATE_LIMIT_REQUESTS=100  # Requests per minute
RATE_LIMIT_WINDOW=60  # Window in seconds

# Deployment Configuration
# ----------------------
RENDER_EXTERNAL_URL=https://waterwise-ai-xce5.onrender.com
RENDER_SERVICE_ID=your_render_service_id

# Optional Feature Flags
# --------------------
ENABLE_FILE_UPLOAD=True
ENABLE_CHAT_HISTORY=True
ENABLE_ADVANCED_LOGGING=False

# Model Fallback Configuration
# ---------------------------
FALLBACK_MODELS=llama2,mistral,phi
MODEL_DOWNLOAD_TIMEOUT=900  # 15 minutes max for model download
